{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f435793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils_functions import *\n",
    "from plan import *\n",
    "import random\n",
    "#from tensorflow.keras import layers\n",
    "#from tensorflow.keras.models import Model\n",
    "import datetime, os\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7177344b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded\n",
      "File loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dict_stati= load_file(\"C:/Users/Francesco/Desktop/dataset/dataset/dizionario_stati\")\n",
    "plansLoaded=load_file(\"C:/Users/Francesco/Desktop/dataset/dataset/plans\")\n",
    "#print(type(plansPickles))\n",
    "#plansList=load_from_pickles(\"C:/Users/Francesco/Desktop/dataset/dataset/dizionario_stati\",plansPickles)\n",
    "#print(plansPickles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "994cd7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ogni stato è un tensore con elementi dtype int8, questi stati vengono raggruppati in un altro tensore che rappresnta la\n",
    "#variabile \"states\" del piano \n",
    "def build_vector(dict, states_list):\n",
    "    l=len(dict)\n",
    "    vector_states=[]\n",
    "    for state in states_list:\n",
    "        vector=np.array([0]*l,dtype=np.int8)\n",
    "        #vector=tf.zeros(l,dtype=np.int8)\n",
    "        for s in state:\n",
    "            for key in dict.keys():\n",
    "                if key==s:\n",
    "                    vector[dict[key]-1]=1\n",
    "                    break\n",
    "        #t=tf.convert_to_tensor(vector,dtype=tf.int8)            \n",
    "        vector_states.append(vector) \n",
    "    r = np.array(vector_states)                          \n",
    "    return r\n",
    "\n",
    "\n",
    "#NON UTILIZZATO ADESSO\n",
    "#shape di ogni singolo elemento (r) è (n x 340) con n che varia su ogni piano, raggruppati sulla base dei piani\n",
    "def build_all_vectors(dict,plans_list):\n",
    "    total=[]\n",
    "    for plan in plans_list:\n",
    "        r=build_vector(dict,plan.states)\n",
    "        total.append(r)\n",
    "    #r = tf.convert_to_tensor(total,dtype=None)                         \n",
    "    return total\n",
    " \n",
    "    \n",
    "#gli stati vengono ordinati (in una lista) singolarmente con shape (1x340), non vengono raggruppati sulla base dei piani\n",
    "#da utilizzare per autoencoder standard\n",
    "def build_all_vectors1x340(dict, plans_list):\n",
    "    l=len(dict)\n",
    "    total=[]\n",
    "    for plan in plans_list:\n",
    "        for state in plan.states:\n",
    "            vector=np.array([0]*l,dtype=np.int8)\n",
    "            for s in state:\n",
    "                for key in dict.keys():\n",
    "                    if key==s:\n",
    "                        vector[dict[key]-1]=1\n",
    "                        break\n",
    "            #t=tf.convert_to_tensor(vector,dtype=tf.int8)            \n",
    "            total.append(vector)\n",
    "    total=np.array(total)        \n",
    "    return total        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8f80382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_states_from_plans_list=build_all_vectors(dict_stati,plansLoaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe83a51",
   "metadata": {},
   "source": [
    "## Preparazione dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d8fed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creazione dataset totale\n",
    "all1x340=build_all_vectors1x340(dict_stati,plansLoaded)\n",
    "random.shuffle(all1x340)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c7364dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1384373, 340)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "int8\n"
     ]
    }
   ],
   "source": [
    "print(all1x340.shape)\n",
    "print(type(all1x340))\n",
    "print(type(all1x340[6]))\n",
    "print(all1x340[6].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea9dd3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creAzione di train, test e validation set,--> input shape per rete = 340\n",
    "#rendere questi set statici, altimenti cambiano sempre ad ogni esecuzione.... es. comprimerli con 7zip o pickle --> DA FARE IN PRIMA POSSIBILE\n",
    "#random.shuffle(all1x340)\n",
    "half=int(len(all1x340)//3)\n",
    "train=all1x340[half:]\n",
    "vt=all1x340[:half]\n",
    "h2=int(len(vt)//2)\n",
    "validation=vt[h2:]\n",
    "test=vt[:h2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f59a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85be87a",
   "metadata": {},
   "source": [
    "## Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00dc9c18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "185/185 [==============================] - 5s 22ms/step - loss: 0.1689 - accuracy: 0.0454 - precision: 0.4060 - recall: 0.0883 - val_loss: 0.1403 - val_accuracy: 0.0513 - val_precision: 0.6572 - val_recall: 0.1589\n",
      "Epoch 2/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.1345 - accuracy: 0.0509 - precision: 0.6692 - recall: 0.1827 - val_loss: 0.1293 - val_accuracy: 0.0467 - val_precision: 0.6723 - val_recall: 0.2124\n",
      "Epoch 3/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.1241 - accuracy: 0.0469 - precision: 0.6857 - recall: 0.2415 - val_loss: 0.1188 - val_accuracy: 0.0613 - val_precision: 0.7079 - val_recall: 0.2610\n",
      "Epoch 4/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.1153 - accuracy: 0.0687 - precision: 0.6961 - recall: 0.2937 - val_loss: 0.1116 - val_accuracy: 0.0876 - val_precision: 0.6998 - val_recall: 0.3143\n",
      "Epoch 5/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.1090 - accuracy: 0.0892 - precision: 0.7021 - recall: 0.3347 - val_loss: 0.1066 - val_accuracy: 0.0974 - val_precision: 0.7006 - val_recall: 0.3609\n",
      "Epoch 6/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.1035 - accuracy: 0.1011 - precision: 0.7127 - recall: 0.3758 - val_loss: 0.1008 - val_accuracy: 0.0956 - val_precision: 0.7194 - val_recall: 0.3957\n",
      "Epoch 7/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0992 - accuracy: 0.1140 - precision: 0.7289 - recall: 0.4077 - val_loss: 0.0990 - val_accuracy: 0.0954 - val_precision: 0.7141 - val_recall: 0.4243\n",
      "Epoch 8/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0958 - accuracy: 0.1388 - precision: 0.7432 - recall: 0.4287 - val_loss: 0.0930 - val_accuracy: 0.1296 - val_precision: 0.7486 - val_recall: 0.4494\n",
      "Epoch 9/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0927 - accuracy: 0.1475 - precision: 0.7535 - recall: 0.4440 - val_loss: 0.0904 - val_accuracy: 0.1399 - val_precision: 0.7678 - val_recall: 0.4500\n",
      "Epoch 10/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0923 - accuracy: 0.1563 - precision: 0.7530 - recall: 0.4469 - val_loss: 0.0932 - val_accuracy: 0.1821 - val_precision: 0.7569 - val_recall: 0.4404\n",
      "Epoch 11/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0901 - accuracy: 0.1595 - precision: 0.7653 - recall: 0.4559 - val_loss: 0.0878 - val_accuracy: 0.1600 - val_precision: 0.7711 - val_recall: 0.4695\n",
      "Epoch 12/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0875 - accuracy: 0.1665 - precision: 0.7735 - recall: 0.4685 - val_loss: 0.0865 - val_accuracy: 0.1654 - val_precision: 0.7900 - val_recall: 0.4603\n",
      "Epoch 13/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0869 - accuracy: 0.1840 - precision: 0.7745 - recall: 0.4713 - val_loss: 0.0868 - val_accuracy: 0.1939 - val_precision: 0.7823 - val_recall: 0.4628\n",
      "Epoch 14/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0852 - accuracy: 0.1903 - precision: 0.7826 - recall: 0.4781 - val_loss: 0.0962 - val_accuracy: 0.2281 - val_precision: 0.7541 - val_recall: 0.4333\n",
      "Epoch 15/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0869 - accuracy: 0.1991 - precision: 0.7761 - recall: 0.4716 - val_loss: 0.0885 - val_accuracy: 0.2141 - val_precision: 0.7890 - val_recall: 0.4461\n",
      "Epoch 16/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0834 - accuracy: 0.1977 - precision: 0.7917 - recall: 0.4836 - val_loss: 0.0823 - val_accuracy: 0.2084 - val_precision: 0.7972 - val_recall: 0.4871\n",
      "Epoch 17/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0847 - accuracy: 0.2015 - precision: 0.7829 - recall: 0.4804 - val_loss: 0.0871 - val_accuracy: 0.2299 - val_precision: 0.7898 - val_recall: 0.4423\n",
      "Epoch 18/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0853 - accuracy: 0.2182 - precision: 0.7848 - recall: 0.4749 - val_loss: 0.0819 - val_accuracy: 0.2148 - val_precision: 0.8035 - val_recall: 0.4822\n",
      "Epoch 19/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0817 - accuracy: 0.2112 - precision: 0.7963 - recall: 0.4904 - val_loss: 0.0810 - val_accuracy: 0.2090 - val_precision: 0.7931 - val_recall: 0.4991\n",
      "Epoch 20/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0811 - accuracy: 0.2087 - precision: 0.7974 - recall: 0.4949 - val_loss: 0.0811 - val_accuracy: 0.2052 - val_precision: 0.8001 - val_recall: 0.4942\n",
      "Epoch 21/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0816 - accuracy: 0.2124 - precision: 0.7981 - recall: 0.4946 - val_loss: 0.0797 - val_accuracy: 0.2154 - val_precision: 0.8049 - val_recall: 0.5010\n",
      "Epoch 22/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0802 - accuracy: 0.2179 - precision: 0.8031 - recall: 0.5016 - val_loss: 0.0784 - val_accuracy: 0.2118 - val_precision: 0.8066 - val_recall: 0.5131\n",
      "Epoch 23/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0797 - accuracy: 0.2183 - precision: 0.8053 - recall: 0.5050 - val_loss: 0.0777 - val_accuracy: 0.2300 - val_precision: 0.8108 - val_recall: 0.5145\n",
      "Epoch 24/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0811 - accuracy: 0.2234 - precision: 0.8007 - recall: 0.5004 - val_loss: 0.0777 - val_accuracy: 0.2337 - val_precision: 0.8200 - val_recall: 0.5099\n",
      "Epoch 25/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0784 - accuracy: 0.2268 - precision: 0.8110 - recall: 0.5114 - val_loss: 0.0768 - val_accuracy: 0.2260 - val_precision: 0.8199 - val_recall: 0.5155\n",
      "Epoch 26/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0774 - accuracy: 0.2288 - precision: 0.8134 - recall: 0.5156 - val_loss: 0.0764 - val_accuracy: 0.2280 - val_precision: 0.8146 - val_recall: 0.5238\n",
      "Epoch 27/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0795 - accuracy: 0.2226 - precision: 0.8082 - recall: 0.5089 - val_loss: 0.0765 - val_accuracy: 0.2251 - val_precision: 0.8242 - val_recall: 0.5142\n",
      "Epoch 28/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0772 - accuracy: 0.2259 - precision: 0.8149 - recall: 0.5171 - val_loss: 0.0761 - val_accuracy: 0.2331 - val_precision: 0.8325 - val_recall: 0.5087\n",
      "Epoch 29/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0782 - accuracy: 0.2276 - precision: 0.8098 - recall: 0.5147 - val_loss: 0.0854 - val_accuracy: 0.2428 - val_precision: 0.7621 - val_recall: 0.4958\n",
      "Epoch 30/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0760 - accuracy: 0.2212 - precision: 0.8225 - recall: 0.5198 - val_loss: 0.0757 - val_accuracy: 0.2190 - val_precision: 0.8185 - val_recall: 0.5247\n",
      "Epoch 31/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0792 - accuracy: 0.2229 - precision: 0.8112 - recall: 0.5112 - val_loss: 0.0763 - val_accuracy: 0.2377 - val_precision: 0.8099 - val_recall: 0.5291\n",
      "Epoch 32/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0758 - accuracy: 0.2214 - precision: 0.8222 - recall: 0.5238 - val_loss: 0.0819 - val_accuracy: 0.2429 - val_precision: 0.7758 - val_recall: 0.5191\n",
      "Epoch 33/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0771 - accuracy: 0.2234 - precision: 0.8206 - recall: 0.5188 - val_loss: 0.0760 - val_accuracy: 0.2257 - val_precision: 0.8320 - val_recall: 0.5174\n",
      "Epoch 34/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0772 - accuracy: 0.2198 - precision: 0.8221 - recall: 0.5186 - val_loss: 0.0742 - val_accuracy: 0.2247 - val_precision: 0.8267 - val_recall: 0.5340\n",
      "Epoch 35/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0756 - accuracy: 0.2179 - precision: 0.8253 - recall: 0.5252 - val_loss: 0.0739 - val_accuracy: 0.2115 - val_precision: 0.8378 - val_recall: 0.5292\n",
      "Epoch 36/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0769 - accuracy: 0.2169 - precision: 0.8243 - recall: 0.5205 - val_loss: 0.0741 - val_accuracy: 0.2168 - val_precision: 0.8399 - val_recall: 0.5269\n",
      "Epoch 37/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0756 - accuracy: 0.2206 - precision: 0.8267 - recall: 0.5253 - val_loss: 0.0743 - val_accuracy: 0.2143 - val_precision: 0.8383 - val_recall: 0.5274\n",
      "Epoch 38/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0786 - accuracy: 0.2204 - precision: 0.8153 - recall: 0.5168 - val_loss: 0.0779 - val_accuracy: 0.2435 - val_precision: 0.8269 - val_recall: 0.5056\n",
      "Epoch 39/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0746 - accuracy: 0.2236 - precision: 0.8344 - recall: 0.5256 - val_loss: 0.0739 - val_accuracy: 0.2198 - val_precision: 0.8338 - val_recall: 0.5300\n",
      "Epoch 40/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0739 - accuracy: 0.2199 - precision: 0.8311 - recall: 0.5321 - val_loss: 0.0740 - val_accuracy: 0.2090 - val_precision: 0.8325 - val_recall: 0.5310\n",
      "Epoch 41/5000\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 0.0752 - accuracy: 0.2202 - precision: 0.8247 - recall: 0.5299 - val_loss: 0.0748 - val_accuracy: 0.2265 - val_precision: 0.8433 - val_recall: 0.5187\n",
      "Epoch 42/5000\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 0.0733 - accuracy: 0.2152 - precision: 0.8355 - recall: 0.5355 - val_loss: 0.0730 - val_accuracy: 0.2168 - val_precision: 0.8345 - val_recall: 0.5396\n",
      "Epoch 43/5000\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 0.0756 - accuracy: 0.2160 - precision: 0.8250 - recall: 0.5293 - val_loss: 0.0726 - val_accuracy: 0.2140 - val_precision: 0.8501 - val_recall: 0.5318\n",
      "Epoch 44/5000\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 0.0725 - accuracy: 0.2104 - precision: 0.8399 - recall: 0.5394 - val_loss: 0.0722 - val_accuracy: 0.2107 - val_precision: 0.8377 - val_recall: 0.5441\n",
      "Epoch 45/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0761 - accuracy: 0.2110 - precision: 0.8238 - recall: 0.5297 - val_loss: 0.0754 - val_accuracy: 0.2257 - val_precision: 0.8333 - val_recall: 0.5236\n",
      "Epoch 46/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0723 - accuracy: 0.2102 - precision: 0.8429 - recall: 0.5394 - val_loss: 0.0724 - val_accuracy: 0.2081 - val_precision: 0.8413 - val_recall: 0.5406\n",
      "Epoch 47/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0760 - accuracy: 0.2139 - precision: 0.8280 - recall: 0.5289 - val_loss: 0.0735 - val_accuracy: 0.2139 - val_precision: 0.8480 - val_recall: 0.5314\n",
      "Epoch 48/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0732 - accuracy: 0.2120 - precision: 0.8426 - recall: 0.5361 - val_loss: 0.0781 - val_accuracy: 0.2216 - val_precision: 0.8034 - val_recall: 0.5383\n",
      "Epoch 49/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0756 - accuracy: 0.2124 - precision: 0.8304 - recall: 0.5311 - val_loss: 0.0753 - val_accuracy: 0.2404 - val_precision: 0.8406 - val_recall: 0.5237\n",
      "Epoch 50/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0728 - accuracy: 0.2116 - precision: 0.8451 - recall: 0.5378 - val_loss: 0.0740 - val_accuracy: 0.2109 - val_precision: 0.8401 - val_recall: 0.5314\n",
      "Epoch 51/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0725 - accuracy: 0.2105 - precision: 0.8432 - recall: 0.5405 - val_loss: 0.0723 - val_accuracy: 0.2156 - val_precision: 0.8411 - val_recall: 0.5435\n",
      "Epoch 52/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0755 - accuracy: 0.2104 - precision: 0.8341 - recall: 0.5308 - val_loss: 0.0719 - val_accuracy: 0.2105 - val_precision: 0.8533 - val_recall: 0.5380\n",
      "Epoch 53/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0720 - accuracy: 0.2075 - precision: 0.8449 - recall: 0.5428 - val_loss: 0.0725 - val_accuracy: 0.2129 - val_precision: 0.8582 - val_recall: 0.5302\n",
      "Epoch 54/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0819 - accuracy: 0.2036 - precision: 0.8188 - recall: 0.5077 - val_loss: 0.0741 - val_accuracy: 0.2096 - val_precision: 0.8474 - val_recall: 0.5285\n",
      "Epoch 55/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0732 - accuracy: 0.2131 - precision: 0.8469 - recall: 0.5332 - val_loss: 0.0751 - val_accuracy: 0.2092 - val_precision: 0.8231 - val_recall: 0.5380\n",
      "Epoch 56/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0726 - accuracy: 0.2143 - precision: 0.8448 - recall: 0.5383 - val_loss: 0.0724 - val_accuracy: 0.2099 - val_precision: 0.8392 - val_recall: 0.5453\n",
      "Epoch 57/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0739 - accuracy: 0.2136 - precision: 0.8365 - recall: 0.5357 - val_loss: 0.0720 - val_accuracy: 0.2121 - val_precision: 0.8535 - val_recall: 0.5378\n",
      "Epoch 58/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0722 - accuracy: 0.2148 - precision: 0.8452 - recall: 0.5411 - val_loss: 0.0720 - val_accuracy: 0.2092 - val_precision: 0.8461 - val_recall: 0.5417\n",
      "Epoch 59/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0789 - accuracy: 0.2177 - precision: 0.8263 - recall: 0.5191 - val_loss: 0.0726 - val_accuracy: 0.2149 - val_precision: 0.8492 - val_recall: 0.5374\n",
      "Epoch 60/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0736 - accuracy: 0.2127 - precision: 0.8398 - recall: 0.5373 - val_loss: 0.0794 - val_accuracy: 0.2187 - val_precision: 0.7953 - val_recall: 0.5257\n",
      "Epoch 61/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0721 - accuracy: 0.2128 - precision: 0.8475 - recall: 0.5415 - val_loss: 0.0717 - val_accuracy: 0.2128 - val_precision: 0.8493 - val_recall: 0.5427\n",
      "Epoch 62/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0718 - accuracy: 0.2100 - precision: 0.8448 - recall: 0.5454 - val_loss: 0.0897 - val_accuracy: 0.1801 - val_precision: 0.7767 - val_recall: 0.5230\n",
      "Epoch 63/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0751 - accuracy: 0.2108 - precision: 0.8359 - recall: 0.5348 - val_loss: 0.0709 - val_accuracy: 0.2084 - val_precision: 0.8479 - val_recall: 0.5505\n",
      "Epoch 64/5000\n",
      "185/185 [==============================] - 3s 14ms/step - loss: 0.0712 - accuracy: 0.2055 - precision: 0.8470 - recall: 0.5481 - val_loss: 0.0719 - val_accuracy: 0.2048 - val_precision: 0.8362 - val_recall: 0.5517\n",
      "Epoch 65/5000\n",
      "185/185 [==============================] - 3s 14ms/step - loss: 0.0729 - accuracy: 0.2039 - precision: 0.8396 - recall: 0.5438 - val_loss: 0.0707 - val_accuracy: 0.2046 - val_precision: 0.8493 - val_recall: 0.5496\n",
      "Epoch 66/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0740 - accuracy: 0.2065 - precision: 0.8375 - recall: 0.5394 - val_loss: 0.0705 - val_accuracy: 0.1975 - val_precision: 0.8611 - val_recall: 0.5431\n",
      "Epoch 67/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0735 - accuracy: 0.2022 - precision: 0.8362 - recall: 0.5415 - val_loss: 0.0735 - val_accuracy: 0.2091 - val_precision: 0.8453 - val_recall: 0.5305\n",
      "Epoch 68/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0710 - accuracy: 0.2024 - precision: 0.8487 - recall: 0.5468 - val_loss: 0.0704 - val_accuracy: 0.1968 - val_precision: 0.8461 - val_recall: 0.5547\n",
      "Epoch 69/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0717 - accuracy: 0.2046 - precision: 0.8432 - recall: 0.5475 - val_loss: 0.0702 - val_accuracy: 0.1980 - val_precision: 0.8465 - val_recall: 0.5543\n",
      "Epoch 70/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0781 - accuracy: 0.1987 - precision: 0.8255 - recall: 0.5303 - val_loss: 0.0714 - val_accuracy: 0.1979 - val_precision: 0.8536 - val_recall: 0.5430\n",
      "Epoch 71/5000\n",
      "185/185 [==============================] - 2s 11ms/step - loss: 0.0706 - accuracy: 0.1980 - precision: 0.8522 - recall: 0.5486 - val_loss: 0.0734 - val_accuracy: 0.1711 - val_precision: 0.8334 - val_recall: 0.5428\n",
      "Epoch 72/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0738 - accuracy: 0.2016 - precision: 0.8356 - recall: 0.5416 - val_loss: 0.0703 - val_accuracy: 0.2011 - val_precision: 0.8601 - val_recall: 0.5469\n",
      "Epoch 73/5000\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.0697 - accuracy: 0.1926 - precision: 0.8545 - recall: 0.5541 - val_loss: 0.0694 - val_accuracy: 0.1900 - val_precision: 0.8536 - val_recall: 0.5573\n",
      "Epoch 74/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0732 - accuracy: 0.1948 - precision: 0.8366 - recall: 0.5471 - val_loss: 0.0726 - val_accuracy: 0.2127 - val_precision: 0.8508 - val_recall: 0.5362\n",
      "Epoch 75/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0698 - accuracy: 0.1938 - precision: 0.8559 - recall: 0.5535 - val_loss: 0.0691 - val_accuracy: 0.1888 - val_precision: 0.8551 - val_recall: 0.5595\n",
      "Epoch 76/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0724 - accuracy: 0.1978 - precision: 0.8399 - recall: 0.5491 - val_loss: 0.0700 - val_accuracy: 0.2029 - val_precision: 0.8576 - val_recall: 0.5527\n",
      "Epoch 77/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0691 - accuracy: 0.1918 - precision: 0.8568 - recall: 0.5583 - val_loss: 0.0689 - val_accuracy: 0.1923 - val_precision: 0.8498 - val_recall: 0.5652\n",
      "Epoch 78/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0713 - accuracy: 0.1990 - precision: 0.8450 - recall: 0.5533 - val_loss: 0.0689 - val_accuracy: 0.1957 - val_precision: 0.8579 - val_recall: 0.5596\n",
      "Epoch 79/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0699 - accuracy: 0.1956 - precision: 0.8499 - recall: 0.5585 - val_loss: 0.0711 - val_accuracy: 0.2057 - val_precision: 0.8479 - val_recall: 0.5506\n",
      "Epoch 80/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0721 - accuracy: 0.1987 - precision: 0.8421 - recall: 0.5527 - val_loss: 0.0708 - val_accuracy: 0.2245 - val_precision: 0.8621 - val_recall: 0.5450\n",
      "Epoch 81/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0687 - accuracy: 0.1947 - precision: 0.8604 - recall: 0.5605 - val_loss: 0.0689 - val_accuracy: 0.1939 - val_precision: 0.8551 - val_recall: 0.5630\n",
      "Epoch 82/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0698 - accuracy: 0.1955 - precision: 0.8516 - recall: 0.5596 - val_loss: 0.0684 - val_accuracy: 0.1914 - val_precision: 0.8591 - val_recall: 0.5641\n",
      "Epoch 83/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0745 - accuracy: 0.1984 - precision: 0.8372 - recall: 0.5462 - val_loss: 0.0693 - val_accuracy: 0.1960 - val_precision: 0.8619 - val_recall: 0.5586\n",
      "Epoch 84/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0684 - accuracy: 0.1909 - precision: 0.8612 - recall: 0.5631 - val_loss: 0.0683 - val_accuracy: 0.1939 - val_precision: 0.8618 - val_recall: 0.5638\n",
      "Epoch 85/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0685 - accuracy: 0.1985 - precision: 0.8562 - recall: 0.5655 - val_loss: 0.0679 - val_accuracy: 0.2024 - val_precision: 0.8523 - val_recall: 0.5736\n",
      "Epoch 86/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0686 - accuracy: 0.2006 - precision: 0.8546 - recall: 0.5662 - val_loss: 0.0682 - val_accuracy: 0.1961 - val_precision: 0.8505 - val_recall: 0.5756\n",
      "Epoch 87/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0694 - accuracy: 0.2003 - precision: 0.8515 - recall: 0.5639 - val_loss: 0.0680 - val_accuracy: 0.2039 - val_precision: 0.8639 - val_recall: 0.5632\n",
      "Epoch 88/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0725 - accuracy: 0.2086 - precision: 0.8430 - recall: 0.5558 - val_loss: 0.0676 - val_accuracy: 0.1909 - val_precision: 0.8635 - val_recall: 0.5690\n",
      "Epoch 89/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0679 - accuracy: 0.2003 - precision: 0.8603 - recall: 0.5688 - val_loss: 0.0675 - val_accuracy: 0.1973 - val_precision: 0.8552 - val_recall: 0.5760\n",
      "Epoch 90/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0742 - accuracy: 0.1988 - precision: 0.8371 - recall: 0.5531 - val_loss: 0.0824 - val_accuracy: 0.2132 - val_precision: 0.8295 - val_recall: 0.4927\n",
      "Epoch 91/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0732 - accuracy: 0.2040 - precision: 0.8577 - recall: 0.5373 - val_loss: 0.0710 - val_accuracy: 0.2002 - val_precision: 0.8611 - val_recall: 0.5496\n",
      "Epoch 92/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0732 - accuracy: 0.2042 - precision: 0.8502 - recall: 0.5459 - val_loss: 0.0702 - val_accuracy: 0.2021 - val_precision: 0.8651 - val_recall: 0.5529\n",
      "Epoch 93/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0707 - accuracy: 0.2019 - precision: 0.8560 - recall: 0.5551 - val_loss: 0.0699 - val_accuracy: 0.2006 - val_precision: 0.8646 - val_recall: 0.5539\n",
      "Epoch 94/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0721 - accuracy: 0.2028 - precision: 0.8501 - recall: 0.5534 - val_loss: 0.0697 - val_accuracy: 0.2095 - val_precision: 0.8670 - val_recall: 0.5562\n",
      "Epoch 95/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0704 - accuracy: 0.1997 - precision: 0.8551 - recall: 0.5590 - val_loss: 0.0711 - val_accuracy: 0.2223 - val_precision: 0.8516 - val_recall: 0.5550\n",
      "Epoch 96/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0694 - accuracy: 0.2018 - precision: 0.8590 - recall: 0.5625 - val_loss: 0.0692 - val_accuracy: 0.2011 - val_precision: 0.8572 - val_recall: 0.5647\n",
      "Epoch 97/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0719 - accuracy: 0.2053 - precision: 0.8500 - recall: 0.5551 - val_loss: 0.0688 - val_accuracy: 0.2002 - val_precision: 0.8647 - val_recall: 0.5633\n",
      "Epoch 98/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0721 - accuracy: 0.2038 - precision: 0.8474 - recall: 0.5548 - val_loss: 0.0696 - val_accuracy: 0.2016 - val_precision: 0.8622 - val_recall: 0.5608\n",
      "Epoch 99/5000\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.0692 - accuracy: 0.1981 - precision: 0.8618 - recall: 0.5628 - val_loss: 0.0692 - val_accuracy: 0.1964 - val_precision: 0.8602 - val_recall: 0.5641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d125be50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 340 #costante\n",
    "\n",
    "#Scelti casulmente al momento.... da rivedere come prima modifica forse\n",
    "hidden_size = 85\n",
    "#hidden_size2 = 85\n",
    "code_size = 17\n",
    "\n",
    "\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=\"C:/Users/Francesco/Desktop/owl-main/logsTf\",histogram_freq=1)\n",
    "\n",
    "]\n",
    "\n",
    "#Cose da fare per migliorare la rete solo dopo aver fatto i primi tentativi con la rete proposta:\n",
    "# * Provare ad aggiungere Regolarizzazione es. L1,L2 e dropout(solo nella fase di encoding)\n",
    "# * Provare swish al posto di relu\n",
    "# * Provare keras.layers.BatchNormalization()\n",
    "# * Fare Hyperparameter Tuning  (ultima) www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams\n",
    "#Salvare i risultati con ogni modifica fatta per scriverli nel report\n",
    "\n",
    "input_layer = Input(shape=(input_size,))\n",
    "hidden_1 = Dense(hidden_size, activation='relu', kernel_initializer=\"he_uniform\")(input_layer)\n",
    "#hidden_3 = Dense(hidden_size, activation='relu', kernel_initializer=\"he_uniform\")(hidden_1)\n",
    "\n",
    "code = Dense(code_size, activation='relu',kernel_initializer=\"he_uniform\")(hidden_1)\n",
    "\n",
    "hidden_2 =Dense(hidden_size, activation='relu',kernel_initializer=\"he_uniform\")(code)\n",
    "#hidden_4 =Dense(hidden_size, activation='relu',kernel_initializer=\"he_uniform\")(hidden_2)\n",
    "output_layer = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "#variare learning_rate beta_1,beta_2, da fare per ultimo\n",
    "#batch_size ???\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='binary_crossentropy',metrics=[\"accuracy\",\"Precision\",\"Recall\"])\n",
    "autoencoder.fit(x=train,y=train, epochs=5000,batch_size=5000, validation_data=(validation,validation), callbacks=my_callbacks,\n",
    "                      )\n",
    "\n",
    " #Gardare i risulati delle metriche su tensorbord                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "283988aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#%tensorboard --logdir logsTf\n",
    "%load_ext tensorboard\n",
    "#Avvio da terminale: spostarsi nella cartella dove è presente la cartella di log, > tensorboard --logdir nomecartella"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb3dc4",
   "metadata": {},
   "source": [
    "# Print di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "369df4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0], shape=(340,), dtype=int8)\n",
      "tf.Tensor(\n",
      "[1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0], shape=(340,), dtype=int8)\n",
      "tf.Tensor(\n",
      "[0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0], shape=(340,), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "print(validation[59])\n",
    "print(test[2000])\n",
    "print(train[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68dbc7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]], shape=(12, 340), dtype=int8)\n",
      "tf.Tensor(\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]], shape=(11, 340), dtype=int8)\n",
      "tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]], shape=(15, 340), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(all_states_from_plans_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b662722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********initial state *******\n",
      "14\n",
      "\n",
      "['clear crate3', 'clear pallet0', 'at crate0 distributor0', 'available hoist4', 'at truck0 distributor0', 'available hoist3', 'available hoist2', 'on crate3 pallet4', 'at crate3 depot1', 'on crate0 pallet1', 'available hoist0', 'clear crate0', 'clear pallet2', 'at truck2 distributor2']\n",
      "******** states *******\n",
      "11\n",
      "\n",
      "[['at truck2 depot1', 'clear crate0', 'available hoist0', 'on crate0 pallet1', 'clear crate3', 'on crate3 pallet4', 'available hoist4', 'at crate0 distributor0', 'available hoist2', 'available hoist3', 'at crate3 depot1', 'clear pallet0', 'clear pallet2', 'at truck0 distributor0'], ['at truck2 depot1', 'lifting hoist2 crate0', 'clear pallet1', 'available hoist0', 'clear crate3', 'on crate3 pallet4', 'available hoist4', 'available hoist3', 'at crate3 depot1', 'clear pallet0', 'clear pallet2', 'at truck0 distributor0'], ['at truck2 depot1', 'clear pallet1', 'in crate0 truck0', 'available hoist0', 'clear crate3', 'on crate3 pallet4', 'available hoist4', 'available hoist2', 'available hoist3', 'at crate3 depot1', 'clear pallet0', 'clear pallet2', 'at truck0 distributor0'], ['at truck2 depot1', 'lifting hoist3 crate3', 'clear pallet4', 'clear pallet1', 'in crate0 truck0', 'available hoist0', 'available hoist4', 'available hoist2', 'clear pallet0', 'clear pallet2', 'at truck0 distributor0'], ['at truck2 depot1', 'clear pallet4', 'clear pallet1', 'in crate3 truck2', 'in crate0 truck0', 'available hoist0', 'available hoist4', 'available hoist2', 'available hoist3', 'clear pallet0', 'clear pallet2', 'at truck0 distributor0'], ['at truck2 depot2', 'clear pallet4', 'clear pallet1', 'in crate3 truck2', 'in crate0 truck0', 'available hoist0', 'available hoist4', 'available hoist2', 'available hoist3', 'clear pallet0', 'clear pallet2', 'at truck0 distributor0'], ['at truck2 depot2', 'clear pallet4', 'clear pallet1', 'in crate0 truck0', 'lifting hoist4 crate3', 'available hoist0', 'available hoist2', 'available hoist3', 'clear pallet0', 'clear pallet2', 'at truck0 distributor0'], ['at truck2 depot2', 'clear pallet4', 'clear pallet1', 'in crate0 truck0', 'at crate3 depot2', 'on crate3 pallet2', 'available hoist0', 'clear crate3', 'available hoist4', 'available hoist2', 'available hoist3', 'clear pallet0', 'at truck0 distributor0'], ['at truck0 distributor2', 'at truck2 depot2', 'clear pallet4', 'clear pallet1', 'in crate0 truck0', 'at crate3 depot2', 'on crate3 pallet2', 'available hoist0', 'clear crate3', 'available hoist4', 'available hoist2', 'available hoist3', 'clear pallet0'], ['at truck0 distributor2', 'at truck2 depot2', 'clear pallet4', 'clear pallet1', 'lifting hoist0 crate0', 'at crate3 depot2', 'on crate3 pallet2', 'clear crate3', 'available hoist4', 'available hoist2', 'available hoist3', 'clear pallet0'], ['at truck0 distributor2', 'at truck2 depot2', 'clear pallet4', 'clear pallet1', 'at crate3 depot2', 'on crate3 pallet2', 'at crate0 distributor2', 'on crate0 pallet0', 'clear crate0', 'available hoist0', 'clear crate3', 'available hoist4', 'available hoist2', 'available hoist3']]\n",
      "******* goals ********\n",
      "2\n",
      "\n",
      "['on crate3 pallet2', 'on crate0 pallet0']\n",
      "\n",
      "\n",
      " -------------  dict stati -----------\n",
      "340\n",
      "\n",
      "{'at truck2 depot1': 1, 'clear crate3': 2, 'clear crate9': 3, 'available hoist4': 4, 'on crate3 pallet1': 5, 'on crate9 pallet0': 6, 'clear crate8': 7, 'on crate8 pallet4': 8, 'at crate3 depot2': 9, 'available hoist2': 10, 'available hoist3': 11, 'at crate9 distributor2': 12, 'available hoist5': 13, 'available hoist0': 14, 'at crate8 depot1': 15, 'available hoist1': 16, 'clear pallet2': 17, 'clear pallet5': 18, 'clear pallet3': 19, 'at truck0 distributor1': 20, 'at truck1 distributor1': 21, 'at truck1 depot2': 22, 'lifting hoist2 crate3': 23, 'clear pallet1': 24, 'in crate3 truck1': 25, 'at truck1 distributor0': 26, 'lifting hoist5 crate3': 27, 'at crate3 distributor0': 28, 'on crate3 pallet5': 29, 'lifting hoist0 crate8': 30, 'clear pallet4': 31, 'in crate8 truck2': 32, 'at truck2 distributor1': 33, 'lifting hoist4 crate8': 34, 'at crate8 distributor1': 35, 'on crate8 pallet2': 36, 'clear crate0': 37, 'on crate0 pallet1': 38, 'on crate3 pallet4': 39, 'at crate0 distributor0': 40, 'at crate3 depot1': 41, 'clear pallet0': 42, 'at truck0 distributor0': 43, 'lifting hoist2 crate0': 44, 'in crate0 truck0': 45, 'lifting hoist3 crate3': 46, 'in crate3 truck2': 47, 'at truck2 depot2': 48, 'lifting hoist4 crate3': 49, 'on crate3 pallet2': 50, 'at truck0 distributor2': 51, 'lifting hoist0 crate0': 52, 'at crate0 distributor2': 53, 'on crate0 pallet0': 54, 'clear crate2': 55, 'on crate2 pallet2': 56, 'at crate7 distributor1': 57, 'at crate2 depot2': 58, 'on crate7 pallet5': 59, 'on crate8 crate7': 60, 'at truck0 depot0': 61, 'lifting hoist4 crate2': 62, 'in crate2 truck1': 63, 'lifting hoist1 crate8': 64, 'clear crate7': 65, 'lifting hoist1 crate7': 66, 'in crate7 truck2': 67, 'lifting hoist2 crate7': 68, 'at crate7 depot1': 69, 'on crate7 pallet4': 70, 'on crate8 pallet5': 71, 'at truck1 distributor2': 72, 'lifting hoist5 crate2': 73, 'at crate2 distributor2': 74, 'on crate2 pallet1': 75, 'lifting hoist3 crate0': 76, 'on crate7 pallet1': 77, 'at crate7 distributor0': 78, 'clear crate6': 79, 'at crate8 depot2': 80, 'at crate5 depot2': 81, 'at crate6 depot2': 82, 'on crate1 crate7': 83, 'at crate4 depot2': 84, 'on crate3 crate1': 85, 'at crate1 distributor0': 86, 'on crate4 crate8': 87, 'on crate5 crate4': 88, 'on crate6 crate5': 89, 'at truck0 depot2': 90, 'lifting hoist0 crate6': 91, 'clear crate5': 92, 'in crate6 truck1': 93, 'lifting hoist0 crate5': 94, 'clear crate4': 95, 'in crate5 truck1': 96, 'lifting hoist0 crate4': 97, 'in crate4 truck1': 98, 'in crate8 truck1': 99, 'on crate6 pallet4': 100, 'in crate0 truck1': 101, 'clear crate1': 102, 'lifting hoist3 crate1': 103, 'in crate1 truck1': 104, 'lifting hoist3 crate7': 105, 'in crate7 truck1': 106, 'lifting hoist3 crate5': 107, 'at crate5 distributor0': 108, 'on crate5 pallet1': 109, 'on crate0 crate5': 110, 'lifting hoist3 crate4': 111, 'on crate4 crate0': 112, 'at crate4 distributor0': 113, 'lifting hoist3 crate8': 114, 'on crate8 crate4': 115, 'at crate8 distributor0': 116, 'lifting hoist0 crate3': 117, 'on crate3 crate6': 118, 'lifting hoist0 crate7': 119, 'on crate7 crate3': 120, 'at crate7 depot2': 121, 'on crate1 pallet5': 122, 'at crate1 depot2': 123, 'at crate8 distributor2': 124, 'on crate0 crate1': 125, 'on crate5 crate0': 126, 'at crate6 distributor2': 127, 'at crate0 depot2': 128, 'on crate9 crate8': 129, 'on crate6 crate9': 130, 'on crate2 crate6': 131, 'in crate4 truck2': 132, 'in crate5 truck2': 133, 'in crate0 truck2': 134, 'at truck2 distributor2': 135, 'in crate2 truck2': 136, 'lifting hoist5 crate6': 137, 'in crate6 truck2': 138, 'lifting hoist5 crate9': 139, 'in crate9 truck2': 140, 'lifting hoist5 crate8': 141, 'lifting hoist5 crate0': 142, 'on crate0 pallet4': 143, 'on crate9 crate0': 144, 'lifting hoist5 crate4': 145, 'at crate4 distributor2': 146, 'on crate4 crate9': 147, 'on crate6 crate1': 148, 'on crate8 crate6': 149, 'on crate5 crate8': 150, 'lifting hoist4 crate1': 151, 'on crate2 pallet4': 152, 'on crate3 pallet3': 153, 'at crate3 distributor2': 154, 'at crate2 depot1': 155, 'at truck2 depot0': 156, 'in crate1 truck2': 157, 'lifting hoist2 crate2': 158, 'lifting hoist2 crate1': 159, 'at crate1 depot1': 160, 'on crate1 pallet4': 161, 'on crate2 pallet3': 162, 'on crate4 pallet3': 163, 'at crate4 depot0': 164, 'at crate6 distributor0': 165, 'at truck0 depot1': 166, 'lifting hoist1 crate1': 167, 'at crate1 distributor1': 168, 'on crate1 pallet1': 169, 'at truck1 depot0': 170, 'lifting hoist4 crate4': 171, 'on crate4 pallet5': 172, 'lifting hoist4 crate6': 173, 'on crate6 crate4': 174, 'lifting hoist5 crate7': 175, 'at crate8 depot0': 176, 'on crate8 pallet3': 177, 'at crate2 depot0': 178, 'at crate9 depot0': 179, 'at crate6 depot0': 180, 'at crate5 depot0': 181, 'at crate0 depot0': 182, 'on crate2 crate8': 183, 'on crate6 crate2': 184, 'on crate0 crate6': 185, 'on crate9 crate5': 186, 'lifting hoist2 crate9': 187, 'lifting hoist2 crate5': 188, 'lifting hoist2 crate6': 189, 'lifting hoist2 crate8': 190, 'at crate7 depot0': 191, 'on crate7 pallet3': 192, 'on crate5 crate7': 193, 'on crate9 pallet5': 194, 'on crate8 crate9': 195, 'on crate0 crate8': 196, 'on crate2 crate4': 197, 'on crate5 pallet3': 198, 'at crate5 distributor1': 199, 'in crate3 truck0': 200, 'in crate9 truck0': 201, 'in crate5 truck0': 202, 'lifting hoist0 crate9': 203, 'lifting hoist1 crate3': 204, 'on crate3 pallet0': 205, 'at crate9 distributor1': 206, 'on crate9 pallet3': 207, 'lifting hoist1 crate5': 208, 'on crate5 crate3': 209, 'at crate3 distributor1': 210, 'on crate5 pallet0': 211, 'at crate9 depot2': 212, 'on crate5 pallet5': 213, 'at truck1 depot1': 214, 'lifting hoist1 crate2': 215, 'at crate5 distributor2': 216, 'at crate1 distributor2': 217, 'on crate9 crate7': 218, 'on crate3 crate9': 219, 'on crate1 crate5': 220, 'on crate8 crate1': 221, 'lifting hoist5 crate1': 222, 'lifting hoist5 crate5': 223, 'in crate2 truck0': 224, 'lifting hoist1 crate9': 225, 'on crate8 pallet0': 226, 'in crate7 truck0': 227, 'on crate1 crate2': 228, 'on crate9 crate1': 229, 'lifting hoist1 crate0': 230, 'on crate0 crate7': 231, 'on crate0 pallet3': 232, 'at crate0 depot1': 233, 'on crate5 pallet2': 234, 'on crate6 crate0': 235, 'at truck2 distributor0': 236, 'at crate9 distributor0': 237, 'on crate9 pallet4': 238, 'lifting hoist0 crate1': 239, 'on crate1 crate8': 240, 'on crate5 crate1': 241, 'on crate3 crate5': 242, 'lifting hoist4 crate0': 243, 'on crate4 pallet4': 244, 'on crate8 crate3': 245, 'on crate3 crate0': 246, 'at crate3 depot0': 247, 'on crate4 crate1': 248, 'at crate4 depot1': 249, 'at crate9 depot1': 250, 'at crate5 depot1': 251, 'on crate7 crate4': 252, 'on crate6 pallet0': 253, 'lifting hoist4 crate9': 254, 'lifting hoist4 crate5': 255, 'lifting hoist4 crate7': 256, 'on crate9 crate6': 257, 'at crate6 depot1': 258, 'on crate6 pallet5': 259, 'on crate0 crate9': 260, 'in crate9 truck1': 261, 'on crate9 pallet1': 262, 'on crate9 crate4': 263, 'on crate2 crate3': 264, 'in crate1 truck0': 265, 'lifting hoist3 crate2': 266, 'on crate6 pallet3': 267, 'on crate4 crate6': 268, 'at crate7 distributor2': 269, 'on crate6 crate3': 270, 'on crate0 crate4': 271, 'on crate7 crate0': 272, 'in crate4 truck0': 273, 'on crate4 crate5': 274, 'on crate2 crate0': 275, 'on crate7 crate6': 276, 'lifting hoist2 crate4': 277, 'on crate2 crate5': 278, 'at crate2 distributor0': 279, 'on crate0 crate2': 280, 'on crate3 crate7': 281, 'on crate4 crate3': 282, 'lifting hoist1 crate4': 283, 'at crate4 distributor1': 284, 'on crate4 pallet2': 285, 'on crate1 pallet3': 286, 'at crate0 distributor1': 287, 'on crate6 crate8': 288, 'on crate5 crate9': 289, 'lifting hoist3 crate9': 290, 'lifting hoist3 crate6': 291, 'on crate0 crate3': 292, 'on crate1 crate0': 293, 'at crate6 distributor1': 294, 'on crate7 pallet2': 295, 'on crate9 crate2': 296, 'on crate0 pallet2': 297, 'on crate1 crate3': 298, 'on crate2 crate1': 299, 'in crate6 truck0': 300, 'on crate2 pallet5': 301, 'at crate1 depot0': 302, 'on crate8 crate2': 303, 'on crate3 crate8': 304, 'on crate6 pallet1': 305, 'on crate7 pallet0': 306, 'on crate4 pallet1': 307, 'on crate8 crate0': 308, 'on crate1 crate4': 309, 'at crate2 distributor1': 310, 'on crate8 pallet1': 311, 'on crate2 crate7': 312, 'on crate5 crate2': 313, 'on crate3 crate2': 314, 'on crate9 crate3': 315, 'on crate1 crate6': 316, 'lifting hoist1 crate6': 317, 'on crate5 crate6': 318, 'on crate3 crate4': 319, 'on crate7 crate8': 320, 'on crate4 crate7': 321, 'on crate2 pallet0': 322, 'lifting hoist0 crate2': 323, 'on crate1 pallet0': 324, 'on crate5 pallet4': 325, 'on crate0 pallet5': 326, 'in crate8 truck0': 327, 'on crate9 pallet2': 328, 'on crate2 crate9': 329, 'on crate4 crate2': 330, 'on crate4 pallet0': 331, 'on crate7 crate2': 332, 'on crate6 crate7': 333, 'on crate7 crate5': 334, 'on crate6 pallet2': 335, 'on crate7 crate1': 336, 'on crate8 crate5': 337, 'on crate1 crate9': 338, 'on crate1 pallet2': 339, 'on crate7 crate9': 340}\n"
     ]
    }
   ],
   "source": [
    "print(\"********initial state *******\")\n",
    "print(len(plansLoaded[1].initial_state))\n",
    "print(\"\")\n",
    "print(plansLoaded[1].initial_state)\n",
    "\n",
    "print(\"******** states *******\")\n",
    "print(len(plansLoaded[1].states))\n",
    "print(\"\")\n",
    "print(plansLoaded[1].states)\n",
    "print(\"******* goals ********\")\n",
    "print(len(plansLoaded[1].goals))\n",
    "print(\"\")\n",
    "print(plansLoaded[1].goals)\n",
    "\n",
    "print(\"\\n\\n -------------  dict stati -----------\")\n",
    "print(len(dict_stati))\n",
    "print(\"\")\n",
    "print(dict_stati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "944bb903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0], shape=(340,), dtype=int8)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0], shape=(340,), dtype=int8)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0], shape=(340,), dtype=int8)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0], shape=(340,), dtype=int8)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0], shape=(340,), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(all1x340[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f079b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9acba0606d7acdc9122521c1e55edc08153e62462fdeed28528cdde632651f64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
