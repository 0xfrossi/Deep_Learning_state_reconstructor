{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f435793",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T07:32:59.387487Z",
     "start_time": "2022-06-22T07:32:56.343304Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils_functions import *\n",
    "from plan import *\n",
    "import random\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ba869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T07:34:04.078007Z",
     "start_time": "2022-06-22T07:34:04.064508Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# controllo di star effettivamente usando la GPU\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177344b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T07:34:17.044405Z",
     "start_time": "2022-06-22T07:34:11.722905Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dict_stati= load_file(\"./dizionario_stati\")\n",
    "plansLoaded=load_file(\"./plans\")\n",
    "#print(type(plansPickles))\n",
    "#plansList=load_from_pickles(\"C:/Users/Francesco/Desktop/dataset/dataset/dizionario_stati\",plansPickles)\n",
    "#print(plansPickles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994cd7db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T07:34:17.059908Z",
     "start_time": "2022-06-22T07:34:17.046407Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#ogni stato è un tensore con elementi dtype int8, questi stati vengono raggruppati in un altro tensore che rappresnta la\n",
    "#variabile \"states\" del piano \n",
    "def build_vector(dict, states_list):\n",
    "    l=len(dict)\n",
    "    vector_states=[]\n",
    "    for state in states_list:\n",
    "        vector=np.array([0]*l,dtype=np.int8)\n",
    "        #vector=tf.zeros(l,dtype=np.int8)\n",
    "        for s in state:\n",
    "            for key in dict.keys():\n",
    "                if key==s:\n",
    "                    vector[dict[key]-1]=1\n",
    "                    break\n",
    "        #t=tf.convert_to_tensor(vector,dtype=tf.int8)            \n",
    "        vector_states.append(vector) \n",
    "    r = np.array(vector_states)                          \n",
    "    return r\n",
    "\n",
    "\n",
    "#NON UTILIZZATO ADESSO\n",
    "#shape di ogni singolo elemento (r) è (n x 340) con n che varia su ogni piano, raggruppati sulla base dei piani\n",
    "def build_all_vectors(dict,plans_list):\n",
    "    total=[]\n",
    "    for plan in plans_list:\n",
    "        r=build_vector(dict,plan.states)\n",
    "        total.append(r)\n",
    "    #r = tf.convert_to_tensor(total,dtype=None)                         \n",
    "    return total\n",
    " \n",
    "    \n",
    "#gli stati vengono ordinati (in una lista) singolarmente con shape (1x340), non vengono raggruppati sulla base dei piani\n",
    "#da utilizzare per autoencoder standard\n",
    "def build_all_vectors1x340(dict, plans_list):\n",
    "    l=len(dict)\n",
    "    total=[]\n",
    "    for plan in plans_list:\n",
    "        for state in plan.states:\n",
    "            vector=np.array([0]*l,dtype=np.int8)\n",
    "            for s in state:\n",
    "                for key in dict.keys():\n",
    "                    if key==s:\n",
    "                        vector[dict[key]-1]=1\n",
    "                        break\n",
    "            #t=tf.convert_to_tensor(vector,dtype=tf.int8)            \n",
    "            total.append(vector)\n",
    "    total=np.array(total)        \n",
    "    return total        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f80382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T07:34:17.137378Z",
     "start_time": "2022-06-22T07:34:17.122378Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_states_from_plans_list=build_all_vectors(dict_stati,plansLoaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe83a51",
   "metadata": {},
   "source": [
    "## Preparazione dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c8c33",
   "metadata": {},
   "source": [
    "### Caricamento dataset statici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1464b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T07:36:38.063103Z",
     "start_time": "2022-06-22T07:34:24.953920Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test=load_file(\"./Dataset/set_test\")\n",
    "train=load_file(\"./Dataset/set_training\")\n",
    "validation=load_file(\"./Dataset/set_validation\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda145f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T07:38:07.897786Z",
     "start_time": "2022-06-22T07:37:21.958785Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test=np.array(test,dtype=np.int8)\n",
    "train=np.array(train,dtype=np.int8)\n",
    "validation=np.array(validation,dtype=np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85be87a",
   "metadata": {},
   "source": [
    "## Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc9c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T07:37:21.324142Z",
     "start_time": "2022-06-22T07:36:38.065104Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Cercare come migliorare l'autoencoder e come interpretare le metriche, \n",
    "# i test per il momento sono abbastanza a meno che non vuoi provare qualcosa di specifico sulla base di qello che trovi\n",
    "\n",
    "#****************************************************************************************************\n",
    "\n",
    "logdir = os.path.join(\"./TestLogs/\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1, write_graph=True, write_images=True)\n",
    "\n",
    "]\n",
    "\n",
    "#Cose da fare per migliorare la rete solo dopo aver fatto i primi tentativi con la rete proposta:\n",
    "# * Provare ad aggiungere Regolarizzazione es. L1,L2 e dropout(solo nella fase di encoding)\n",
    "# * Provare swish al posto di relu\n",
    "# * Provare tf.keras.layers.BatchNormalization()(var_layer) \n",
    "# * Fare Hyperparameter Tuning  (ultima) www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams\n",
    "#Salvare i risultati con ogni modifica fatta per scriverli nel report\n",
    "\n",
    "input_size = 340 #costante\n",
    "\n",
    "#Scelti casulmente al momento.... da rivedere come prima modifica forse\n",
    "hidden_size = 170\n",
    "#hidden_size2 = 85\n",
    "code_size = 85\n",
    "\n",
    "input_layer = Input(shape=(input_size,))\n",
    "hidden_1 = Dense(hidden_size, activation='swish', kernel_initializer=\"he_uniform\", )(input_layer)\n",
    "#hidden_3 = Dense(hidden_size, activation='relu', kernel_initializer=\"he_uniform\")(hidden_1)\n",
    "\n",
    "code = Dense(code_size, activation='swish',kernel_initializer=\"he_uniform\",)(hidden_1)\n",
    "hidden_2 =Dense(hidden_size, activation='swish',kernel_initializer=\"he_uniform\",)(code)\n",
    "#hidden_4 =Dense(hidden_size, activation='relu',kernel_initializer=\"he_uniform\")(hidden_2)\n",
    "\n",
    "output_layer = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "#variare learning_rate beta_1,beta_2, da fare per ultimo\n",
    "#batch_size ???\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy',metrics=[\"accuracy\",\"Precision\",\"Recall\"])\n",
    "autoencoder.fit(x=train,y=train, epochs=500,batch_size=300000, validation_data=(validation,validation), callbacks=my_callbacks,\n",
    "                      )\n",
    "\n",
    " #Gardare i risulati delle metriche su tensorbord                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283988aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T13:15:32.761190Z",
     "start_time": "2022-06-18T13:15:32.749190Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logsTf\n",
    "%load_ext tensorboard\n",
    "#Avvio da terminale: spostarsi nella cartella dove è presente la cartella di log, > tensorboard --logdir nomecartella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd27c49",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9acba0606d7acdc9122521c1e55edc08153e62462fdeed28528cdde632651f64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
