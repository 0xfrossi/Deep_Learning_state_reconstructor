{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f20066a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:45:07.386749Z",
     "start_time": "2022-06-26T13:45:07.373749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "283f868d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:45:07.402254Z",
     "start_time": "2022-06-26T13:45:07.388249Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils_functions import *\n",
    "from plan import *\n",
    "import random\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11c66693",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:45:07.417748Z",
     "start_time": "2022-06-26T13:45:07.404250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# controllo di star effettivamente usando la GPU\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "043c6639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:45:13.152250Z",
     "start_time": "2022-06-26T13:45:07.419750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded\n",
      "File loaded\n"
     ]
    }
   ],
   "source": [
    "dict_stati= load_file(\"./dizionario_stati\")\n",
    "plansLoaded=load_file(\"./plans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "433c7390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:45:13.167749Z",
     "start_time": "2022-06-26T13:45:13.153749Z"
    }
   },
   "outputs": [],
   "source": [
    "#ogni stato è un tensore con elementi dtype int8, questi stati vengono raggruppati in un altro tensore che rappresnta la\n",
    "#variabile \"states\" del piano \n",
    "\n",
    "def build_vector(dict, states_list):\n",
    "    l=len(dict)\n",
    "    vector_states=[]\n",
    "    for state in states_list:\n",
    "        vector=np.array([0]*l,dtype=np.int8)\n",
    "        #vector=tf.zeros(l,dtype=np.int8)\n",
    "        for s in state:\n",
    "            for key in dict.keys():\n",
    "                if key==s:\n",
    "                    vector[dict[key]-1]=1\n",
    "                    break\n",
    "        #t=tf.convert_to_tensor(vector,dtype=tf.int8)            \n",
    "        vector_states.append(vector) \n",
    "    r = np.array(vector_states)                          \n",
    "    return r\n",
    "\n",
    "#NON UTILIZZATO ADESSO\n",
    "#shape di ogni singolo elemento (r) è (n x 340) con n che varia su ogni piano, raggruppati sulla base dei piani\n",
    "\n",
    "def build_all_vectors(dict,plans_list):\n",
    "    total=[]\n",
    "    for plan in plans_list:\n",
    "        r=build_vector(dict,plan.states)\n",
    "        total.append(r)\n",
    "    #r = tf.convert_to_tensor(total,dtype=None)                         \n",
    "    return total\n",
    " \n",
    "    \n",
    "#gli stati vengono ordinati (in una lista) singolarmente con shape (1x340), non vengono raggruppati sulla base dei piani\n",
    "#da utilizzare per autoencoder standard\n",
    "\n",
    "def build_all_vectors1x340(dict, plans_list):\n",
    "    l=len(dict)\n",
    "    total=[]\n",
    "    for plan in plans_list:\n",
    "        for state in plan.states:\n",
    "            vector=np.array([0]*l,dtype=np.int8)\n",
    "            for s in state:\n",
    "                for key in dict.keys():\n",
    "                    if key==s:\n",
    "                        vector[dict[key]-1]=1\n",
    "                        break\n",
    "            #t=tf.convert_to_tensor(vector,dtype=tf.int8)            \n",
    "            total.append(vector)\n",
    "    total=np.array(total)        \n",
    "    return total        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f8594",
   "metadata": {},
   "source": [
    "## Preparazione dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6a441",
   "metadata": {},
   "source": [
    "### Caricamento dataset statici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "548e70da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:47:31.720249Z",
     "start_time": "2022-06-26T13:45:13.169251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded\n",
      "File loaded\n",
      "File loaded\n"
     ]
    }
   ],
   "source": [
    "test=load_file(\"./Dataset/set_test\")\n",
    "train=load_file(\"./Dataset/set_training\")\n",
    "validation=load_file(\"./Dataset/set_validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4775b2e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:48:22.916248Z",
     "start_time": "2022-06-26T13:47:31.723750Z"
    }
   },
   "outputs": [],
   "source": [
    "test=np.array(test,dtype=np.int8)\n",
    "train=np.array(train,dtype=np.int8)\n",
    "validation=np.array(validation,dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2f44f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:48:22.947251Z",
     "start_time": "2022-06-26T13:48:22.917751Z"
    }
   },
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"./TestLogs/\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1, write_graph=True, write_images=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a30a81ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:48:22.978239Z",
     "start_time": "2022-06-26T13:48:22.948749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Per il test mi limito a tunare il numero di unità nascoste.\n",
    "# Se poi funziona, dovrebbe trattarsi solo di scrivere meccanicamente le righe restanti.\n",
    "input_size = 340\n",
    "HP_HIDDEN_SIZE = hp.HParam('hidden_size', hp.Discrete([160, 180]))\n",
    "code_size = 85\n",
    "METRIC_LOSS = 'loss'\n",
    "\n",
    "with tf.summary.create_file_writer('./logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_HIDDEN_SIZE],\n",
    "        metrics=[hp.Metric(METRIC_LOSS, display_name='loss')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "461982bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:48:22.993252Z",
     "start_time": "2022-06-26T13:48:22.980246Z"
    }
   },
   "outputs": [],
   "source": [
    "# def train_model(hparams):\n",
    "#     input_layer = Input(shape=(input_size,))\n",
    "#     hidden_1 = Dense(hparams[HP_HIDDEN_SIZE], activation='swish', kernel_initializer=\"he_uniform\", )(input_layer)\n",
    "#     code = Dense(code_size, activation='swish',kernel_initializer=\"he_uniform\",)(hidden_1)\n",
    "#     hidden_2 =Dense(hparams[HP_HIDDEN_SIZE], activation='swish',kernel_initializer=\"he_uniform\",)(code)\n",
    "#     output_layer = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "    \n",
    "#     autoencoder = Model(input_layer, output_layer)\n",
    "#     autoencoder.compile(\n",
    "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "#         loss='binary_crossentropy',\n",
    "#         metrics=['Precision'],\n",
    "#     )\n",
    "#     autoencoder.fit(\n",
    "#         x=train,y=train,\n",
    "#         epochs=15,\n",
    "#         batch_size=1000,\n",
    "#         validation_data=(validation,validation),\n",
    "#         callbacks=my_callbacks,\n",
    "#     )\n",
    "    \n",
    "#     _, Precision = model.evaluate(x=test, y=test)\n",
    "#     return Precision\n",
    "\n",
    "def train_model(hparams):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_size,)),\n",
    "        tf.keras.layers.Dense(hparams[HP_HIDDEN_SIZE], activation=tf.nn.swish),\n",
    "        tf.keras.layers.Dense(code_size, activation=tf.nn.swish),\n",
    "        tf.keras.layers.Dense(hparams[HP_HIDDEN_SIZE], activation=tf.nn.swish),\n",
    "        tf.keras.layers.Dense(input_size, activation=tf.nn.sigmoid),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['loss'],\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        x=train,y=train,\n",
    "        epochs=1500,\n",
    "        batch_size=10000,\n",
    "        validation_data=(validation,validation),\n",
    "        callbacks=my_callbacks,\n",
    "    )\n",
    "    _, epoch_loss = model.evaluate(x=test, y=test)\n",
    "    return epoch_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6268b6a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:48:23.008529Z",
     "start_time": "2022-06-26T13:48:22.994753Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        loss = train_model(hparams)\n",
    "        tf.summary.scalar(METRIC_LOSS, loss, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68c87c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:48:23.597532Z",
     "start_time": "2022-06-26T13:48:23.010030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'hidden_size': 160}\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/1500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:862 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:852 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:807 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:439 update_state\n        self.build(y_pred, y_true)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:361 build\n        self._metrics = nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1376 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1474 map_structure_with_tuple_paths_up_to\n        results = [\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1475 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1378 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:485 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:485 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:504 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:3694 get\n        return deserialize(str(identifier))\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:3650 deserialize\n        return deserialize_keras_object(\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:704 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--- Starting trial: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m run_name)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m({h\u001b[38;5;241m.\u001b[39mname: hparams[h] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hparams})\n\u001b[1;32m---> 10\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogs/hparam_tuning/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m session_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_dir, hparams)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mcreate_file_writer(run_dir)\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m      3\u001b[0m     hp\u001b[38;5;241m.\u001b[39mhparams(hparams)\n\u001b[1;32m----> 4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mscalar(METRIC_LOSS, loss, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(hparams)\u001b[0m\n\u001b[0;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     27\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(input_size,)),\n\u001b[0;32m     28\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(hparams[HP_HIDDEN_SIZE], activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mswish),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(input_size, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msigmoid),\n\u001b[0;32m     32\u001b[0m ])\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     34\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[0;32m     35\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     36\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     37\u001b[0m )\n\u001b[1;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m _, epoch_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x\u001b[38;5;241m=\u001b[39mtest, y\u001b[38;5;241m=\u001b[39mtest)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1193\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1189\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1190\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1191\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1192\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1193\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1194\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1195\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    763\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3066\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3460\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3463\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3293\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3295\u001b[0m ]\n\u001b[0;32m   3296\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3297\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3306\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3310\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3311\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3312\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3313\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3314\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3315\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1007\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1012\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    665\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 668\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    669\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:994\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    993\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    995\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:862 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:852 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:807 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:439 update_state\n        self.build(y_pred, y_true)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:361 build\n        self._metrics = nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1376 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1474 map_structure_with_tuple_paths_up_to\n        results = [\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1475 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1378 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:485 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:485 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:504 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:3694 get\n        return deserialize(str(identifier))\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:3650 deserialize\n        return deserialize_keras_object(\n    C:\\Users\\lucal\\miniconda3\\envs\\EnvAutoEncoder\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:704 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for h_units in HP_HIDDEN_SIZE.domain.values:\n",
    "    hparams= {\n",
    "        HP_HIDDEN_SIZE: h_units,\n",
    "    }\n",
    "    run_name = \"run-%d\" % session_num\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    run('logs/hparam_tuning/' + run_name, hparams)\n",
    "    session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62185a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T13:48:23.599533Z",
     "start_time": "2022-06-26T13:48:23.599533Z"
    }
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs/hparam_tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
