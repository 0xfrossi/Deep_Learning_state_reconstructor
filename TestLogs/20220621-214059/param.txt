input_size = 340 #costante

#Scelti casulmente al momento.... da rivedere come prima modifica forse
hidden_size = 170
#hidden_size2 = 85
code_size = 85

input_layer = Input(shape=(input_size,))
hidden_1 = Dense(hidden_size, activation='relu', kernel_initializer="he_uniform",kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4) )(input_layer)
b1=tf.keras.layers.BatchNormalization()(hidden_1)
#hidden_3 = Dense(hidden_size, activation='relu', kernel_initializer="he_uniform")(hidden_1)

code = Dense(code_size, activation='relu',kernel_initializer="he_uniform",kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4))(b1)
b2=tf.keras.layers.BatchNormalization()(code)
hidden_2 =Dense(hidden_size, activation='relu',kernel_initializer="he_uniform",kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4))(b2)
#hidden_4 =Dense(hidden_size, activation='relu',kernel_initializer="he_uniform")(hidden_2)
b3=tf.keras.layers.BatchNormalization()(hidden_2)
output_layer = Dense(input_size, activation='sigmoid')(b3)

autoencoder = Model(input_layer, output_layer)
#variare learning_rate beta_1,beta_2, da fare per ultimo
#batch_size ???
autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.002), loss='binary_crossentropy',metrics=["accuracy","Precision","Recall"])
autoencoder.fit(x=train,y=train, epochs=500,batch_size=50000, validation_data=(validation,validation), callbacks=my_callbacks,
                      )